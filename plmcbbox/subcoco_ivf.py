# AUTOGENERATED! DO NOT EDIT! File to edit: 30_subcoco_ivf.ipynb (unless otherwise specified).

__all__ = ['fetch_data', 'empty_list', 'CocoDatasetStats', 'load_stats', 'SubCocoParser']

# Cell
import fastai
import icevision
import icevision.backbones as backbones
import icevision.models
import icevision.models.efficientdet as efficientdet
import icevision.models.rcnn.faster_rcnn as faster_rcnn
import icevision.tfms as tfms
import json
import matplotlib.pyplot as plt
import numpy as np
import os
import pickle
import PIL
import pytorch_lightning as pl
import re
import requests
import tarfile
import sys
import torch
import torchvision
import xml.etree.ElementTree

from albumentations import ShiftScaleRotate
from collections import defaultdict
from functools import reduce
from fastai.callback.training import GradientAccumulation
from fastai.callback.tracker import EarlyStoppingCallback, SaveModelCallback, TerminateOnNaNCallback
from icevision.core import BBox, ClassMap
from icevision.data import Dataset
from icevision.metrics.coco_metric import COCOMetricType, COCOMetric
from icevision.parsers import Parser
from icevision.parsers.mixins import LabelsMixin, BBoxesMixin, FilepathMixin, SizeMixin
from icevision.utils import denormalize_imagenet
from icevision.visualize.show_data import *
from IPython.utils import io
from pathlib import Path
from PIL import Image, ImageStat
from tqdm import tqdm
from typing import Hashable, List, Union

# Cell

def fetch_data(url:str, datadir: Path, tgt_fname:str, chunk_size:int=8*1024, quiet=False):
    dest = datadir/tgt_fname
    if not quiet: print(f"Downloading from {url} to {dest}...")
    with requests.get(url, stream=True, timeout=10) as response:
        content_len = int(response.headers['content-length'])
        with open(dest, 'wb') as f:
            with tqdm(total=content_len) as pbar:
                nbytes = 0
                num_chunks = 0
                for chunk in response.iter_content(chunk_size=chunk_size):
                    chunk_len = len(chunk)
                    nbytes += chunk_len
                    num_chunks += 1
                    f.write(chunk)
                    pbar.update(chunk_len)

    with tarfile.open(dest, 'r') as tar:
        extracted = []
        for item in tar:
            tar.extract(item, datadir)
            extracted.append(item.name)

    if not quiet: print(f"Downloaded {nbytes} from {url} to {dest}, extracted in {datadir}: {extracted[:3]},...,{extracted[-3:]}")

# Cell

# cannot use lambda as pickling may fail when saving models
def empty_list(): return []

class CocoDatasetStats():
    # num_cats
    # num_imgs
    # num_bboxs
    # cat2name
    # class_map
    # lbl2cat
    # cat2lbl
    # img2fname
    # imgs
    # img2cat2bs
    # img2cbs
    # cat2ibs
    # avg_ncats_per_img
    # avg_nboxs_per_img
    # avg_nboxs_per_cat
    # img2sz
    # chn_means
    # chn_stds
    # avg_width
    # avg_height
    def __init__(self, ann:dict, img_dir:Path):

        self.img_dir = img_dir
        self.num_cats = len(ann['categories'])
        self.num_imgs = len(ann['images'])
        self.num_bboxs = len(ann['annotations'])

        # build cat id to name, assign FRCNN
        self.cat2name = { c['id']: c['name'] for c in ann['categories'] }
        self.class_map = ClassMap(list(self.cat2name.values()))

        # need to translate coco subset category id to indexable label id
        # expected labels w 0 = background
        self.lbl2cat = { self.class_map.get_name(n): c for c, n in self.cat2name.items() }
        self.cat2lbl = { c: l for l, c in self.lbl2cat.items() }
        self.lbl2cat[0] = (0, 'background')
        self.cat2lbl[0] = 0

        # img_id to file map
        self.img2fname = { img['id']:img['file_name'] for img in ann['images'] }
        self.imgs = [ { 'id':img_id, 'file_name':img_fname } for (img_id, img_fname) in self.img2fname.items() ]

        # build up some maps for later analysis
        self.img2l2bs = {}
        self.img2lbs = defaultdict(empty_list)
        self.l2ibs = defaultdict(empty_list)
        anno_id = 0
        for a in ann['annotations']:
            img_id = a['image_id']
            cat_id = a['category_id']
            lbl_id = self.cat2lbl[cat_id]
            l2bs_for_img = self.img2l2bs.get(img_id, { l:[] for l in range(1+len(self.cat2name))})
            (x, y, w, h) = a['bbox']
            if w > 1 and h > 1:
                b = (x, y, w, h)
                ib = (img_id, *b)
                lb = (lbl_id, *b)
                l2bs_for_img[lbl_id].append(b)
                self.l2ibs[lbl_id].append(ib)
                self.img2lbs[img_id].append(lb)
            self.img2l2bs[img_id] = l2bs_for_img

        acc_ncats_per_img = 0.0
        acc_nboxs_per_img = 0.0
        for img_id, l2bs in self.img2l2bs.items():
            acc_ncats_per_img += len(l2bs)
            for lbl_id, bs in l2bs.items():
                acc_nboxs_per_img += len(bs)

        self.avg_ncats_per_img = acc_ncats_per_img/self.num_imgs
        self.avg_nboxs_per_img = acc_nboxs_per_img/self.num_imgs

        acc_nboxs_per_cat = 0.0
        for lbl_id, ibs in self.l2ibs.items():
            acc_nboxs_per_cat += len(ibs)

        self.avg_nboxs_per_cat = acc_nboxs_per_cat/self.num_cats

        # compute Images per channel means and std deviation using PIL.ImageStat.Stat()

        self.img2sz = {}
        n = 0
        mean = np.zeros((3,))
        stddev = np.zeros((3,))
        avgw = 0
        avgh = 0
        for img in tqdm(self.imgs):
            img_id = img['id']
            fname = img_dir/img['file_name']
            n = n + 1
            img = Image.open(fname)
            istat = ImageStat.Stat(img)
            width, height = img.size
            avgw = (width + (n-1)*avgw)/n
            avgh = (height + (n-1)*avgh)/n
            self.img2l2bs[img_id][0].append( (width/3, height/3, width/3, height/3, ) ) # hack to add a backgrnd box
            mean = (istat.mean + (n-1)*mean)/n
            stddev = (istat.stddev + (n-1)*stddev)/n
            self.img2sz[fname] = (width, height)

        self.chn_means = mean
        self.chn_stds = stddev
        self.avg_width = avgw
        self.avg_height = avgh

def load_stats(ann:dict, img_dir:Path, force_reload:bool=False):
    stats_fpath = img_dir/'stats.pkl'
    stats = None
    if os.path.isfile(stats_fpath) and not force_reload:
        try:
            stats = pickle.load( open(stats_fpath, "rb" ) )
        except Exception as e:
            print(f"Failed to read precomputed stats: {e}")

    if stats == None:
        stats = CocoDatasetStats(ann, img_dir)
        pickle.dump(stats, open(stats_fpath, "wb" ) )

    return stats

# Cell
class SubCocoParser(Parser, LabelsMixin, BBoxesMixin, FilepathMixin, SizeMixin):
    def __init__(self, stats:CocoDatasetStats):
        self.stats = stats
        self.data = [] # list of tuple of form (img_id, wth, ht, bbox, label_id, img_path)
        for img_id, imgfname in stats.img2fname.items():
            imgf = stats.img_dir/imgfname
            width, height = stats.img2sz[imgf]
            bboxs = []
            lids = []
            for lid, x, y, w, h in stats.img2lbs[img_id]:
                if lid != None and x >= 0 and y >= 0 and w > 0 and h > 0:
                    b = [int(x), int(y), int(w), int(h)]
                    l = int(lid)
                    bboxs.append(b)
                    lids.append(l)
                else:
                    print(f"warning: skipping lxywh of {lid, x, y, w, h}")
            self.data.append( (img_id, width, height, bboxs, lids, imgf, ) )

    def __iter__(self):
        yield from iter(self.data)

    def __len__(self):
        return len(self.data)

    def imageid(self, o) -> Hashable:
        return o[0]

    def filepath(self, o) -> Union[str, Path]:
        return o[5]

    def height(self, o) -> int:
        return o[2]

    def width(self, o) -> int:
        return o[1]

    def labels(self, o) -> List[int]:
        return o[4]

    def bboxes(self, o) -> List[BBox]:
        return [BBox.from_xywh(x,y,w,h) for x,y,w,h in o[3]]

# Cell
if __name__ == "__main__":
    projroot = Path.home()/"Projects"/"plmcbbox"
    datadir = projroot/"workspace"
    froot = "coco_sample"
    fname = f"{froot}.tgz"
    url = f"https://s3.amazonaws.com/fast-ai-coco/{fname}"
    json_fname = datadir/froot/'annotations'/'train_sample.json'
    img_dir = datadir/froot/'train_sample'
    if not os.path.isdir(datadir/froot):
        fetch_data(url, datadir, fname, chunk_size=1024*1024)
    with open(json_fname, 'r') as json_f:
        train_json = json.load(json_f)
    stats = load_stats(train_json, img_dir=img_dir)
    parser = SubCocoParser(stats)
    train_records, valid_records = parser.parse()
    bs=32
    acc_cycs = 4
    size=384
    train_tfms = tfms.A.Adapter([*tfms.A.aug_tfms(size=size, presize=size+128), tfms.A.Normalize(mean=stats.chn_means, std=stats.chn_stds)])
    valid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(size), tfms.A.Normalize(mean=stats.chn_means, std=stats.chn_stds)])
    backbone_name = "tf_efficientdet_lite0"
    model = efficientdet.model(model_name=backbone_name, img_size=size, num_classes=len(stats.class_map))
    train_ds = Dataset(train_records, train_tfms)
    valid_ds = Dataset(valid_records, valid_tfms)
    train_dl = efficientdet.train_dl(train_ds, batch_size=bs//acc_cycs, num_workers=4, shuffle=True)
    valid_dl = efficientdet.valid_dl(valid_ds, batch_size=bs//acc_cycs, num_workers=4, shuffle=False)
    monitor_metric = 'COCOMetric'
    metrics = [ COCOMetric(metric_type=COCOMetricType.bbox)]
    save_model_fname=f'subcoco-{size}'
    callbacks=[
        TerminateOnNaNCallback(),
        GradientAccumulation(bs),
        SaveModelCallback(fname=save_model_fname, monitor=monitor_metric),
        EarlyStoppingCallback(monitor=monitor_metric, min_delta=0.001, patience=40)
    ]

    learn = efficientdet.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics, cbs=callbacks)
    learn.freeze()
    learn.fine_tune(100, 0.01, freeze_epochs=10)
    model_save_path = projroot/"models"/f"{save_model_fname}-final.pth"
    torch.save(model.state_dict(), model_save_path)