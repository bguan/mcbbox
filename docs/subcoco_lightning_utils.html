---

title: Pytorch Lightning Specific Utilities


keywords: fastai
sidebar: home_sidebar



nb_path: "20_subcoco_lightning_utils.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 20_subcoco_lightning_utils.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Python ver 3.8.5 (default, Jul 28 2020, 12:59:40) 
[GCC 9.3.0], torch 1.7.0, torchvision 0.8.1, pytorch_lightning 1.0.4, Albumentation 0.5.0
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Python ver 3.8.5 (default, Jul 28 2020, 12:59:40) 
[GCC 9.3.0], torch 1.7.0, torchvision 0.8.1, pytorch_lightning 1.0.4, Albumentation 0.5.0
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/brian/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.
  and should_run_async(code)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Wrap-Data-Loading-Logic-using-Pytorch-Lightning">Wrap Data Loading Logic using Pytorch-Lightning<a class="anchor-link" href="#Wrap-Data-Loading-Logic-using-Pytorch-Lightning"> </a></h2><p>In order to use Pytorch Lightning to load data, we need to define a DataModule to encapsulate all the data loading logic. At first I thought I can reuse CocoDetect() from torchvision but it uses cocoapi downstream and expects json annotation file to be of this <a href="https://cocodataset.org/#format-data">format</a>:</p>

<pre><code>annotation{
    "id": int,
    "image_id": int,
    "category_id": int,
    "segmentation": RLE or [polygon],
    "area": float,
    "bbox": [x,y,width,height],
    "iscrowd": 0 or 1,
}</code></pre>
<p>Tiny and Sample Coco's train.json file only has a subset of the above fields:</p>

<pre><code>“Annotations”: [
    {
      "image_id": 542959,
      "bbox": [
        32.52,
        86.34,
        8.53,
        9.41
      ],
      "category_id": 62
    },
    ...
]</code></pre>
<p>Thus we will need to make a Dataset to handle it properly.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SubCocoDataset" class="doc_header"><code>class</code> <code>SubCocoDataset</code><a href="https://github.com/bguan/mcbbox/tree/master/mcbbox/subcoco_lightning_utils.py#L43" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SubCocoDataset</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwds</code></strong>) :: <code>VisionDataset</code></p>
</blockquote>
<p>Simulate what torchvision.CocoDetect() returns for target given fastai's coco subsets
Args:
    root (string): Root directory where images are downloaded to.
    stats (CocoDatasetStats):</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Test w/o Augmentations</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Verify the image transformation works using Albumentation, especially random transform to both image and target.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Custom-DataModule">Custom DataModule<a class="anchor-link" href="#Custom-DataModule"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SubCocoDataModule" class="doc_header"><code>class</code> <code>SubCocoDataModule</code><a href="https://github.com/bguan/mcbbox/tree/master/mcbbox/subcoco_lightning_utils.py#L128" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SubCocoDataModule</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwargs</code></strong>) :: <code>LightningDataModule</code></p>
</blockquote>
<p>A DataModule standardizes the training, val, test splits, data preparation and transforms.
The main advantage is consistent data splits, data preparation and transforms across models.</p>
<p>Example::</p>

<pre><code>class MyDataModule(LightningDataModule):
    def __init__(self):
        super().__init__()
    def prepare_data(self):
        # download, split, etc...
        # only called on 1 GPU/TPU in distributed
    def setup(self):
        # make assignments here (val/train/test split)
        # called on every process in DDP
    def train_dataloader(self):
        train_split = Dataset(...)
        return DataLoader(train_split)
    def val_dataloader(self):
        val_split = Dataset(...)
        return DataLoader(val_split)
    def test_dataloader(self):
        test_split = Dataset(...)
        return DataLoader(test_split)

</code></pre>
<p>A DataModule implements 5 key methods:</p>
<ul>
<li><strong>prepare_data</strong> (things to do on 1 GPU/TPU not on every GPU/TPU in distributed mode).</li>
<li><strong>setup</strong>  (things to do on every accelerator in distributed mode).</li>
<li><strong>train_dataloader</strong> the training dataloader.</li>
<li><strong>val_dataloader</strong> the val dataloader(s).</li>
<li><strong>test_dataloader</strong> the test dataloader(s).</li>
</ul>
<p>This allows you to share a full dataset without explaining how to download,
split transform and process the data</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Export-to-Regular-Python-Script-as-'subcoco_lightning_util.py'">Export to Regular Python Script as 'subcoco_lightning_util.py'<a class="anchor-link" href="#Export-to-Regular-Python-Script-as-'subcoco_lightning_util.py'"> </a></h2>
</div>
</div>
</div>
</div>
 

