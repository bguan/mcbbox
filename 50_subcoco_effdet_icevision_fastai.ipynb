{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp subcoco_effdet_icevision_fastai\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Object Detection using Icevision w/ FastAI\n",
    "\n",
    "I was unable to make much progress using Pytorch Lightning & Torch Vision on a tiny subset of Coco Dataset. \n",
    "I got a model to run for hundreds of epochs, with seemingly improving training loss, but prediction is still garbage.\n",
    "\n",
    "So I decided to get an end to end object detection working example before diving back in. This time I chose https://github.com/airctic/icevision\n",
    "\n",
    "Following their [first example](https://airctic.com/examples/training/) for FastAI..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import fastai\n",
    "import glob\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import PIL\n",
    "import re\n",
    "import requests\n",
    "import tarfile\n",
    "import sys\n",
    "import torch\n",
    "import torch.multiprocessing\n",
    "import torchvision\n",
    "import xml.etree.ElementTree\n",
    "\n",
    "from albumentations import ShiftScaleRotate\n",
    "from collections import defaultdict\n",
    "from fastai.test_utils import synth_learner\n",
    "from fastai.learner import Learner\n",
    "from fastai.callback.training import GradientAccumulation\n",
    "from fastai.callback.tracker import Callback, EarlyStoppingCallback, SaveModelCallback\n",
    "from IPython.utils import io\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageStat\n",
    "from shutil import copyfile, rmtree\n",
    "from tqdm import tqdm\n",
    "from typing import Hashable, List, Tuple, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need some magic to make notebook work in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/', force_remount=True)\n",
    "    os.chdir('/content/drive/My Drive/ColabData')\n",
    "    print(f'Current Directory is now {os.getcwd()}')\n",
    "    !wget -O 'mcbbox/subcoco_utils.py' https://raw.githubusercontent.com/bguan/mcbbox/master/mcbbox/subcoco_utils.py\n",
    "    !pip install pytorch_lightning torchvision gpumonitor\n",
    "else:\n",
    "    from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nArguments for call are not valid.\nThe following variants are available:\n  \n  aten::remainder.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -> (Tensor(a!)):\n  Expected a value of type 'Tensor' for argument 'self' but instead found type 'str'.\n  \n  aten::remainder.Scalar(Tensor self, Scalar other) -> (Tensor):\n  Expected a value of type 'Tensor' for argument 'self' but instead found type 'str'.\n  \n  aten::remainder.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -> (Tensor(a!)):\n  Expected a value of type 'Tensor' for argument 'self' but instead found type 'str'.\n  \n  aten::remainder.Tensor(Tensor self, Tensor other) -> (Tensor):\n  Expected a value of type 'Tensor' for argument 'self' but instead found type 'str'.\n  \n  aten::remainder.int(int a, int b) -> (int):\n  Expected a value of type 'int' for argument 'a' but instead found type 'str'.\n  \n  aten::remainder.float(float a, float b) -> (float):\n  Expected a value of type 'float' for argument 'a' but instead found type 'str'.\n  \n  aten::remainder.int_float(int a, float b) -> (float):\n  Expected a value of type 'int' for argument 'a' but instead found type 'str'.\n  \n  aten::remainder.float_int(float a, int b) -> (float):\n  Expected a value of type 'float' for argument 'a' but instead found type 'str'.\n  \n  aten::remainder(Scalar a, Scalar b) -> (Scalar):\n  Expected a value of type 'number' for argument 'a' but instead found type 'str'.\n\nThe original call is:\n  File \"/usr/local/lib/python3.8/dist-packages/effdet-0.1.6-py3.8.egg/effdet/object_detection/box_list.py\", line 149\n        \"\"\"\n        if not self.has_field(field):\n            raise ValueError('field %s does not exist' % field)\n                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n        self.data[field] = value\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-71f902d1ff37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0micevision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0micevision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbones\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbackbones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0micevision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0micevision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefficientdet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mefficientdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/icevision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0micevision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0micevision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0micevision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0micevision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtfms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0micevision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/icevision/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0micevision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0micevision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0micevision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimageio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0micevision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_files\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0micevision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/icevision/utils/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m ]\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0micevision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/icevision/imports.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Soft imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0micevision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoft_dependencies\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSoftDependencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mSoftDependencies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfastai\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/icevision/soft_dependencies.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mSoftDependencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SoftDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/icevision/soft_dependencies.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch_lightning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoft_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pytorch_lightning\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malbumentations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoft_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"albumentations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoft_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"effdet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoft_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wandb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/icevision/soft_dependencies.py\u001b[0m in \u001b[0;36msoft_import\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoft_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_backward_compatible\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m<frozen zipimport>\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/effdet-0.1.6-py3.8.egg/effdet/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mefficientdet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEfficientDet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbench\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDetBenchPredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDetBenchTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munwrap_bench\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCOCOEvaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFastMapEvalluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_efficientdet_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_detection_model_configs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfactory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_model_from_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_backward_compatible\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m<frozen zipimport>\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/effdet-0.1.6-py3.8.egg/effdet/bench.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelEma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0manchors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAnchorLabeler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_detections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_DETECTION_POINTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDetectionLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_backward_compatible\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m<frozen zipimport>\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/effdet-0.1.6-py3.8.egg/effdet/anchors.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatched_nms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_small_boxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0meffdet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_detection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArgMaxMatcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFasterRcnnBoxCoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBoxList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIouSimilarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTargetAssigner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msoft_nms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatched_soft_nms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_backward_compatible\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m<frozen zipimport>\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/effdet-0.1.6-py3.8.egg/effdet/object_detection/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# https://github.com/tensorflow/tpu/tree/master/models/official/retinanet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0margmax_matcher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArgMaxMatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbox_coder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFasterRcnnBoxCoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbox_list\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBoxList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_backward_compatible\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m<frozen zipimport>\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/effdet-0.1.6-py3.8.egg/effdet/object_detection/box_coder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbox_list\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBoxList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Box coder types.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_backward_compatible\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m<frozen zipimport>\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(self, fullname)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/effdet-0.1.6-py3.8.egg/effdet/object_detection/box_list.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mBoxList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;34m\"\"\"Box collection.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb)\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_rcb\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m             \u001b[0m_rcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_jit_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateResolutionCallbackFromFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_frames_up\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m         \u001b[0m_compile_and_register_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqualified_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36m_compile_and_register_class\u001b[0;34m(obj, rcb, qualified_name)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_jit_class_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mdefaults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrontend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_args_for_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_script_class_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqualified_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_script_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqualified_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nArguments for call are not valid.\nThe following variants are available:\n  \n  aten::remainder.Scalar_out(Tensor self, Scalar other, *, Tensor(a!) out) -> (Tensor(a!)):\n  Expected a value of type 'Tensor' for argument 'self' but instead found type 'str'.\n  \n  aten::remainder.Scalar(Tensor self, Scalar other) -> (Tensor):\n  Expected a value of type 'Tensor' for argument 'self' but instead found type 'str'.\n  \n  aten::remainder.Tensor_out(Tensor self, Tensor other, *, Tensor(a!) out) -> (Tensor(a!)):\n  Expected a value of type 'Tensor' for argument 'self' but instead found type 'str'.\n  \n  aten::remainder.Tensor(Tensor self, Tensor other) -> (Tensor):\n  Expected a value of type 'Tensor' for argument 'self' but instead found type 'str'.\n  \n  aten::remainder.int(int a, int b) -> (int):\n  Expected a value of type 'int' for argument 'a' but instead found type 'str'.\n  \n  aten::remainder.float(float a, float b) -> (float):\n  Expected a value of type 'float' for argument 'a' but instead found type 'str'.\n  \n  aten::remainder.int_float(int a, float b) -> (float):\n  Expected a value of type 'int' for argument 'a' but instead found type 'str'.\n  \n  aten::remainder.float_int(float a, int b) -> (float):\n  Expected a value of type 'float' for argument 'a' but instead found type 'str'.\n  \n  aten::remainder(Scalar a, Scalar b) -> (Scalar):\n  Expected a value of type 'number' for argument 'a' but instead found type 'str'.\n\nThe original call is:\n  File \"/usr/local/lib/python3.8/dist-packages/effdet-0.1.6-py3.8.egg/effdet/object_detection/box_list.py\", line 149\n        \"\"\"\n        if not self.has_field(field):\n            raise ValueError('field %s does not exist' % field)\n                             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n        self.data[field] = value\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import icevision\n",
    "import icevision.backbones as backbones\n",
    "import icevision.models\n",
    "import icevision.models.efficientdet as efficientdet\n",
    "import icevision.models.rcnn.faster_rcnn as faster_rcnn\n",
    "import icevision.tfms as tfms\n",
    "\n",
    "from albumentations import ShiftScaleRotate\n",
    "from gpumonitor.monitor import GPUStatMonitor\n",
    "from gpumonitor.callbacks.lightning import PyTorchGpuMonitorCallback\n",
    "from icevision.core import BBox, ClassMap, BaseRecord\n",
    "from icevision.parsers import Parser\n",
    "from icevision.parsers.mixins import LabelsMixin, BBoxesMixin, FilepathMixin, SizeMixin\n",
    "from icevision.data import Dataset\n",
    "from icevision.metrics.coco_metric import COCOMetricType, COCOMetric\n",
    "from icevision.utils import denormalize_imagenet\n",
    "from icevision.visualize.show_data import *\n",
    "\n",
    "from mcbbox.subcoco_utils import *\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    monitor = GPUStatMonitor(delay=1)\n",
    "\n",
    "print(f\"Python ver {sys.version}, torch {torch.__version__}, torchvision {torchvision.__version__}, fastai {fastai.__version__}, icevision {icevision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the Run\n",
    "\n",
    "Centralize all the training run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test = True\n",
    "if test:\n",
    "    img_sz, bs, acc, workers, head_runs, full_runs = 128, 4, 8, 1, 1, 1\n",
    "    datadir, url, img_subdir = '/tmp', 'http://files.fast.ai/data/examples/coco_tiny.tgz', 'train'\n",
    "else:\n",
    "    img_sz, bs, acc, workers, head_runs, full_runs = 384, 6, 6, 4, 5, 20\n",
    "    datadir, url, img_subdir = 'workspace', 'https://s3.amazonaws.com/fast-ai-coco/coco_sample.tgz', 'train_sample'\n",
    "    \n",
    "stem = Path(url).stem\n",
    "img_dir=f'{datadir}/{stem}/{img_subdir}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a Sample of COCO Data\n",
    "\n",
    "The full COCO Dataset is huge (~50GB?). For my self education exploring object detection, with the intention of using pretrained model in transfer learning, it is not practical to deal with dataset this big as my first project.  Luckily, the kind folks at [FastAI](https://fast.ai) have prepared some convenient subsets, the medium size 3GB https://s3.amazonaws.com/fast-ai-coco/coco_sample.tgz seems like a good candidate.  The 800KB \"http://files.fast.ai/data/examples/coco_tiny.tgz\" on the other hand seems way too small, thus may not have enough data for adequate training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_json = fetch_subcoco(datadir=datadir, url=url, img_subdir=img_subdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Annotations\n",
    "\n",
    "Let's load and inspect the annotation file that comes with the coco tiny dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json['categories'], train_json['images'][0], [a for a in train_json['annotations'] if a['image_id']==train_json['images'][0]['id'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digest the Dataset for useful Stats\n",
    "\n",
    "Do some basic analysis of the data to get numbers like total images, boxes, and average box count per image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = load_stats(train_json, img_dir=img_dir, force_reload=False)\n",
    "print(\n",
    "    f\"Categories {stats.num_cats}, Images {stats.num_imgs}, Boxes {stats.num_bboxs}, avg (w,h) {(stats.avg_width, stats.avg_height)}\"\n",
    "    f\"avg cats/img {stats.avg_ncats_per_img:.1f}, avg boxs/img {stats.avg_nboxs_per_img:.1f}, avg boxs/cat {stats.avg_nboxs_per_cat:.1f}.\")\n",
    "\n",
    "print(f\"Image means by channel {stats.chn_means}, std.dev by channel {stats.chn_stds}\")\n",
    "stats.num_imgs, stats.lbl2name, stats.lbl2cat, stats.cat2lbl, stats.lbl2name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Parser for Icevision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SubCocoParser(Parser, LabelsMixin, BBoxesMixin, FilepathMixin, SizeMixin):\n",
    "    def __init__(self, stats:CocoDatasetStats, min_margin_ratio = 0, min_width_height_ratio = 0, quiet = True):\n",
    "        self.stats = stats\n",
    "        self.data = [] # list of tuple of form (img_id, wth, ht, bbox, label_id, img_path)\n",
    "        skipped = 0\n",
    "        for img_id, imgfname in stats.img2fname.items():\n",
    "            imgf = stats.img_dir/imgfname\n",
    "            if not os.path.isfile(imgf):\n",
    "                skipped += 1\n",
    "                continue\n",
    "            width, height = stats.img2sz[img_id]\n",
    "            bboxs = []\n",
    "            lids = []\n",
    "            for lid, x, y, w, h in stats.img2lbs[img_id]:\n",
    "                if lid != None and box_within_bounds(x, y, w, h, width, height, min_margin_ratio, min_width_height_ratio):\n",
    "                    b = [int(x), int(y), int(w), int(h)]\n",
    "                    l = int(lid)\n",
    "                    bboxs.append(b)\n",
    "                    lids.append(l)\n",
    "                else:\n",
    "                    if not quiet: print(f\"warning: skipping lxywh of {lid, x, y, w, h}\")\n",
    "\n",
    "            if len(bboxs) > 0:\n",
    "                self.data.append( (img_id, width, height, bboxs, lids, imgf, ) )\n",
    "            else:\n",
    "                skipped += 1\n",
    "\n",
    "        print(f\"Skipped {skipped} out of {stats.num_imgs} images\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield from iter(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def imageid(self, o) -> Hashable:\n",
    "        return o[0]\n",
    "\n",
    "    def filepath(self, o) -> Union[str, Path]:\n",
    "        return o[5]\n",
    "\n",
    "    def height(self, o) -> int:\n",
    "        return o[2]\n",
    "\n",
    "    def width(self, o) -> int:\n",
    "        return o[1]\n",
    "\n",
    "    def labels(self, o) -> List[int]:\n",
    "        return o[4]\n",
    "\n",
    "    def bboxes(self, o) -> List[BBox]:\n",
    "        return [BBox.from_xywh(x,y,w,h) for x,y,w,h in o[3]]\n",
    "\n",
    "    def image_width_height(self, o) -> Tuple[int, int]:\n",
    "        img_id = o[0]\n",
    "        return self.stats.img2sz[img_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Using Custom Parser\n",
    "\n",
    "To prevent bounding boxes being too close to margin or too small, especially after augmentation which performs transformations. \n",
    "I would set min_margin_ratio = 0.05, min_width_height_ratio = 0.05.  \n",
    "\n",
    "However, IceVision 2.0 now has autofix which should address these issues, it does take a long time to run though..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def parse_subcoco(stats:CocoDatasetStats)->List[List[BaseRecord]]:\n",
    "    parser = SubCocoParser(stats, min_margin_ratio = 0.05, min_width_height_ratio = 0.05)\n",
    "    train_records, valid_records = parser.parse(autofix=False)\n",
    "    return train_records, valid_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_records, valid_records = parse_subcoco(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shows images with corresponding labels and boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = ClassMap(list(stats.lbl2name.values()))\n",
    "show_records(train_records[:4], ncols=2, class_map=class_map, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom FastAI Callback to Include Metric in Save Model Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SaveModelDupBestCallback(SaveModelCallback):\n",
    "    \"Extend SaveModelCallback to save a duplicate with metric added to end of filename\"\n",
    "    def __init__(self, monitor='valid_loss', comp=None, min_delta=0., fname='model', every_epoch=False, with_opt=False, reset_on_fit=True):\n",
    "        super().__init__(\n",
    "            monitor=monitor, comp=comp, min_delta=min_delta, reset_on_fit=reset_on_fit,\n",
    "            fname=fname, every_epoch=every_epoch, with_opt=with_opt, \n",
    "        )\n",
    "\n",
    "    def after_epoch(self):\n",
    "        \"Compare the value monitored to its best score and save if best.\"\n",
    "        super().after_epoch()\n",
    "        if self.new_best or self.epoch==0:\n",
    "            last_saved = self.last_saved_path\n",
    "            saved_stem = last_saved.stem\n",
    "            backup_stem = f'{saved_stem}@{self.epoch:03d}_{self.monitor}={self.best:.3f}'\n",
    "            backup_file = backup_stem+(last_saved.suffix)\n",
    "            backup_path = last_saved.parent / backup_file\n",
    "            print(f'Backup {last_saved} as {backup_path}')\n",
    "            if last_saved != backup_path: copyfile(last_saved, backup_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can I unit test this? Copy idea from [FastAI Callback](https://github.com/fastai/fastai/blob/master/nbs/17_callback.tracker.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "pid = os.getpid()\n",
    "testpath = Path(f'/tmp/test-{pid}')\n",
    "learn = synth_learner(n_trn=2, path=testpath)\n",
    "bestcb = SaveModelDupBestCallback()\n",
    "learn.fit(n_epoch=1, cbs=bestcb)  # First epoch should trigger best \n",
    "assert (testpath/'models/model.pth').exists()\n",
    "best = bestcb.best\n",
    "bestpath = f'models/model@000_valid_loss={best:.3f}.pth'\n",
    "assert (testpath/bestpath).exists(), f'Expect {bestpath} to exist!'\n",
    "rmtree(testpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Transforms, Model, Training and Validation Dataloaders, Learners\n",
    "\n",
    "* Define transforms - using Albumentations transforms out of the box. \n",
    "* Use them to construct Datasets and Dataloaders. \n",
    "* Make a Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FastGPUMonitorCallback(Callback):\n",
    "    def __init__(self, delay=1, display_options=None):\n",
    "        super(FastGPUMonitorCallback, self).__init__()\n",
    "        self.delay = delay\n",
    "        self.display_options = display_options if display_options else {}\n",
    "        \n",
    "    def before_epoch(self):\n",
    "        self.monitor = GPUStatMonitor(self.delay, self.display_options)\n",
    "\n",
    "    def after_epoch(self):\n",
    "        self.monitor.stop()\n",
    "        print(\"\")\n",
    "        self.monitor.display_average_stats_per_gpu()\n",
    "        \n",
    "def gen_transforms_and_learner(stats:CocoDatasetStats, \n",
    "                               train_records:List[BaseRecord], \n",
    "                               valid_records:List[BaseRecord], \n",
    "                               img_sz=128, \n",
    "                               bs=4, \n",
    "                               acc_cycs=8, \n",
    "                               num_workers=2):\n",
    "    train_tfms = tfms.A.Adapter([\n",
    "        *tfms.A.aug_tfms(\n",
    "            size=img_sz,\n",
    "            presize=img_sz+128,\n",
    "            shift_scale_rotate = tfms.A.ShiftScaleRotate(shift_limit=.025, scale_limit=0.025, rotate_limit=9)\n",
    "        ),\n",
    "        tfms.A.Normalize(mean=stats.chn_means/255, std=stats.chn_stds/255)\n",
    "    ]) \n",
    "    valid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(img_sz), tfms.A.Normalize()])\n",
    "    train_ds = Dataset(train_records, train_tfms)\n",
    "    valid_ds = Dataset(valid_records, valid_tfms)\n",
    "    # Using gradient accumulation to process minibatch of 32 images in 8 loops, i.e. 8 images per loop.\n",
    "    # I ran this model w img 512x512x3 on my Dell XPS15 w GTX-1050 with 4GB VRAM, 16GM RAM, ~20min/epoch.\n",
    "    backbone_name = \"tf_efficientdet_lite0\"\n",
    "    model = efficientdet.model(model_name=backbone_name, img_size=img_sz, num_classes=len(stats.lbl2name))\n",
    "    train_dl = efficientdet.train_dl(train_ds, batch_size=bs, num_workers=num_workers, shuffle=True)\n",
    "    valid_dl = efficientdet.valid_dl(valid_ds, batch_size=bs, num_workers=max(1,num_workers//2), shuffle=False)\n",
    "\n",
    "    monitor_metric = 'COCOMetric'\n",
    "    metrics = [ COCOMetric(metric_type=COCOMetricType.bbox)]\n",
    "\n",
    "    save_model_fname=f'{backbone_name}-{img_sz}'\n",
    "    callbacks=[\n",
    "        GradientAccumulation(bs*acc_cycs),\n",
    "        SaveModelDupBestCallback(fname=save_model_fname, monitor=monitor_metric),\n",
    "        EarlyStoppingCallback(monitor=monitor_metric, min_delta=0.001, patience=10),\n",
    "        FastGPUMonitorCallback(delay=1)\n",
    "    ]\n",
    "\n",
    "    learn = efficientdet.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics, cbs=callbacks)\n",
    "    learn.freeze()\n",
    "\n",
    "    return valid_tfms, learn, backbone_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_tfms, learn, backbone_name = gen_transforms_and_learner(stats, train_records, valid_records, \n",
    "                                                            img_sz=img_sz, bs=bs, acc_cycs=acc, num_workers=workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have experimented with other models available out of box in IceVision, but ***efficientdet*** works the best. You can replace backbone_name, backbone, model, with the following values to test.\n",
    "\n",
    "***backbone_name***\n",
    "* \"resnet_fpn.resnet18\"\n",
    "\n",
    "***backbone***\n",
    "* backbones.resnet_fpn.resnet18(pretrained=True)\n",
    "* backbones.resnet_fpn.resnet34(pretrained=True)\n",
    "* backbones.resnet_fpn.resnet50(pretrained=True) # Default\n",
    "* backbones.resnet_fpn.resnet101(pretrained=True)\n",
    "* backbones.resnet_fpn.resnet152(pretrained=True)\n",
    "* backbones.resnet_fpn.resnext50_32x4d(pretrained=True)\n",
    "* backbones.resnet_fpn.resnext101_32x8d(pretrained=True)\n",
    "* backbones.resnet_fpn.wide_resnet50_2(pretrained=True)\n",
    "* backbones.resnet_fpn.wide_resnet101_2(pretrained=True)\n",
    "\n",
    "***model***\n",
    "* faster_rcnn.model(backbone=backbone, num_classes=len(stats.lbl2name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train using FastAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only do this if GPU avail, otherwise Github CI times out\n",
    "# if torch.cuda.is_available():\n",
    "#     learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# Wrap in function this doesn't run upon import or when generating docs\n",
    "def run_training(learn:Learner, min_lr=0.05, head_runs=1, full_runs=1):\n",
    "    monitor.display_average_stats_per_gpu()\n",
    "    print(f\"Training for {head_runs}+{full_runs} epochs at min LR {min_lr}\")\n",
    "    learn.fine_tune(full_runs, min_lr, freeze_epochs=head_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only do this if GPU avail, otherwise Github CI times out\n",
    "if torch.cuda.is_available():\n",
    "    run_training(learn, min_lr=0.01, head_runs=head_runs, full_runs=full_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only do this if GPU avail, otherwise Github CI times out\n",
    "if torch.cuda.is_available():\n",
    "    infer_ds = Dataset(valid_records[:4], inf_tfms)\n",
    "    infer_dl = efficientdet.infer_dl(infer_ds, batch_size=4, shuffle=True)\n",
    "    samples, preds = efficientdet.predict_dl(learn.model, infer_dl)\n",
    "    imgs = [sample[\"img\"] for sample in samples]\n",
    "    show_preds(\n",
    "        imgs=imgs[:4],\n",
    "        preds=preds[:4],\n",
    "        class_map=class_map,\n",
    "        denormalize_fn=denormalize_imagenet,\n",
    "        ncols=1,\n",
    "        figsize=(36,27)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, training after only 2 epochs does not produce a usable model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Final Model Explicitly\n",
    "\n",
    "Saving it explicitly after all the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def save_final(learn:Learner, save_model_fpath:str):\n",
    "    torch.save(learn.model.state_dict(), save_model_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_saved_model_fpath = f\"models/{backbone_name}-subcoco-{img_sz}-runs-{head_runs}+{full_runs}-final.pth\"\n",
    "save_final(learn, final_saved_model_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference w/ Pretrained Model\n",
    "\n",
    "Load a pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = efficientdet.model(model_name=backbone_name, num_classes=len(stats.lbl2name), img_size=img_sz)\n",
    "pretrained_model.load_state_dict(torch.load(final_saved_model_fpath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Inference with first 4 of the validation image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    infer_ds = Dataset(valid_records[:4], inf_tfms)\n",
    "    infer_dl = efficientdet.infer_dl(infer_ds, batch_size=4, shuffle=False)\n",
    "    samples, preds = efficientdet.predict_dl(pretrained_model.cuda(), infer_dl)\n",
    "    imgs = [sample[\"img\"] for sample in samples]\n",
    "    show_preds(\n",
    "        imgs=imgs[:4],\n",
    "        preds=preds[:4],\n",
    "        class_map=class_map,\n",
    "        denormalize_fn=denormalize_imagenet,\n",
    "        ncols=1,\n",
    "        figsize=(36,27)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
