# AUTOGENERATED! DO NOT EDIT! File to edit: 30_subcoco_pl.ipynb (unless otherwise specified).

__all__ = ['FRCNN', 'digest_pred']

# Cell
import json, os, requests, sys, tarfile, torch, torchvision
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import numpy as np
import pickle
import pytorch_lightning as pl
import torch.nn.functional as F

from collections import defaultdict
from IPython.utils import io
from pathlib import Path
from PIL import Image
from PIL import ImageStat

from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval

from pytorch_lightning.callbacks import ModelCheckpoint
from pytorch_lightning import *

from torch import nn
from torch import optim
from torch.utils.data import DataLoader, random_split

from torchvision import transforms
from torchvision.datasets import CocoDetection
from torchvision.models.detection import FasterRCNN
from torchvision.models.detection.rpn import AnchorGenerator
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor

from tqdm import tqdm

from .subcoco_utils import *

# Cell

class FRCNN(LightningModule):
    def __init__(self, lbl2cat):
        super(FRCNN, self).__init__()
        self.categories = [ {'id': lid, 'name': f"{cid}" } for lid, cid in lbl2cat.items() ]
        self.num_classes = len(self.categories)

        self.model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)

        # lock the pretrained model body
        for param in self.model.parameters():
            param.requires_grad = False

        # get number of input features for the classifier
        self.in_features = self.model.roi_heads.box_predictor.cls_score.in_features

        # replace the pre-trained head with a new one, which is trainable
        self.model.roi_heads.box_predictor = FastRCNNPredictor(self.in_features, self.num_classes)

    def training_step(self, train_batch, batch_idx):
        x, y = train_batch
        losses = self.model(x, y)
        loss = sum(losses.values())
        result = TrainResult(loss)
        result.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)
        return result

    def metrics(self, preds, targets):
        accu = torch.zeros((len(preds), 1))
        for i, (p,t) in enumerate(zip(preds, targets)):
            accu[i] = accuracy_1img(p, t, .3, .3)
        return torch.tensor(accu)

    def validation_step(self, val_batch, batch_idx):
        # validation runs the model in eval mode, so Y is prediction, not losses
        xs, ys = val_batch
        preds = self.model(xs, ys)
        accu = self.metrics(preds, ys)
        return {'val_acc': accu} # should add 'val_acc' accuracy e.g. MAP, MAR etc

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)
        return optimizer

    def validation_epoch_end(self, outputs):
        # called at the end of the validation epoch, but gradient accumulation may result in last row being different size
        val_accs = np.concatenate([ (o['val_acc']).numpy() for o in outputs ])
        avg_acc = val_accs.mean()
        tensorboard_logs = {'val_acc': avg_acc}
        return {'val_acc': avg_acc, 'logs': tensorboard_logs}

    def forward(self, x):
        self.model.eval()
        pred = self.model(x)
        return pred

# Cell
def digest_pred(l2c, pred, cutoff=0.5):
    scores = pred['scores']
    pass_idxs = (scores > cutoff).nonzero(as_tuple=False)
    lbls = pred['labels'][pass_idxs]
    bboxs = pred['boxes'][pass_idxs]
    c2ibs = defaultdict(lambda: [])
    for i,lb in enumerate(zip(lbls, bboxs)):
        l,b = lb
        x,y,w,h = b[0]
        c = l2c[l.item()]
        ibs = c2ibs[c]
        ibs.append((i,x.item(),y.item(),w.item(),h.item()))
        c2ibs[c] = ibs
    return c2ibs