# AUTOGENERATED! DO NOT EDIT! File to edit: 30_subcoco_pl.ipynb (unless otherwise specified).

__all__ = ['datadir', 'froot', 'fname', 'url', 'json_fname', 'img_dir', 'stats', 'run_training', 'frcnn_model',
           'save_final']

# Cell
import json, os, requests, sys, tarfile, torch, torchvision
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import numpy as np
import pickle
import pytorch_lightning as pl
import torch.nn.functional as F

from collections import defaultdict
from IPython.utils import io
from pathlib import Path
from PIL import Image
from PIL import ImageStat

from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval

from pytorch_lightning.callbacks import ModelCheckpoint
from pytorch_lightning import LightningDataModule, LightningModule, Trainer
from pytorch_lightning.core.step_result import TrainResult

from torch import nn
from torch import optim
from torch.utils.data import DataLoader, random_split

from torchvision import transforms
from torchvision.datasets import CocoDetection
from torchvision.models.detection import FasterRCNN
from torchvision.models.detection.rpn import AnchorGenerator
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor

from tqdm import tqdm

from .subcoco_utils import *

# Cell
datadir = Path("workspace")

froot = "coco_sample"
fname = f"{froot}.tgz"
url = f"https://s3.amazonaws.com/fast-ai-coco/{fname}"
json_fname = datadir/froot/'annotations'/'train_sample.json'
img_dir = datadir/froot/'train_sample'

if not os.path.isdir(datadir/froot):
    fetch_data(url, datadir, fname, chunk_size=1024*1024)

# Cell
with open(json_fname, 'r') as json_f:
    train_json = json.load(json_f)

# Cell
stats = load_stats(train_json, img_dir=img_dir, force_reload=False)

# Cell
frcnn_model = FRCNN(lbl2name=stats.lbl2name, lr=0.01)

def run_training(img_sz=384, bs=12, acc=3, workers=4, head_runs=50, full_runs=200):
    print(f"Training with image size {img_sz}, {head_runs}+{full_runs} epochs.")
    subcoco_dm = SubCocoDataModule(img_dir, stats, resize=(img_sz,img_sz), bs=bs, workers=workers)
    chkpt_cb = ModelCheckpoint(
        filepath="models/FRCNN-"+froot+"-{epoch}-{val_acc:.2f}.ckpt",
        save_last=True,
        monitor='val_acc',
        mode='max',
        verbose=True,
    )
    # train head only
    trainer = Trainer(gpus=1, max_epochs=head_runs, checkpoint_callback=chkpt_cb, accumulate_grad_batches=acc)
    trainer.fit(frcnn_model, subcoco_dm)

    frcnn_model.unfreeze() # allow finetuning of the backbone

    # finetune head and backbone
    trainer = Trainer(gpus=1, max_epochs=full_runs, checkpoint_callback=chkpt_cb, accumulate_grad_batches=acc)
    trainer.fit(frcnn_model, subcoco_dm)

# Cell
def save_final():
    model_save_path = f"models/FRCNN-{froot}-final.saved"
    torch.save(frcnn_model.model.state_dict(), model_save_path)