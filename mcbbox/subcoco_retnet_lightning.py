# AUTOGENERATED! DO NOT EDIT! File to edit: 50_subcoco_retinanet_lightning.ipynb.ipynb (unless otherwise specified).

__all__ = ['RetinaNetModule', 'run_training', 'save_final']

# Cell
import cv2, json, os, requests, sys, tarfile, torch, torchvision
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import numpy as np
import pickle
import random
import torch.nn.functional as F
import torch.multiprocessing

from collections import defaultdict
from functools import reduce
from IPython.utils import io
from pathlib import Path
from PIL import Image
from PIL import ImageStat

from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval

from tqdm import tqdm
from typing import Hashable, List, Tuple, Union

# Cell
import albumentations as A
import pytorch_lightning as pl
from albumentations.pytorch import ToTensorV2
from gpumonitor.monitor import GPUStatMonitor
from gpumonitor.callbacks.lightning import PyTorchGpuMonitorCallback
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping
from pytorch_lightning import LightningDataModule, LightningModule, Trainer
from pytorch_lightning.core.step_result import TrainResult
from torch import nn
from torch import optim
from torch.nn.modules import module
from torch.utils.data import DataLoader, random_split
from torchvision.models.detection import RetinaNet, retinanet_resnet50_fpn
from torchvision import transforms
from .subcoco_utils import *
from .subcoco_lightning_utils import *

torch.multiprocessing.set_sharing_strategy('file_system')
print(f"Python ver {sys.version}, torch {torch.__version__}, torchvision {torchvision.__version__}, pytorch_lightning {pl.__version__}, Albumentation {A.__version__}")
if torch.cuda.is_available():
    monitor = GPUStatMonitor(delay=1)
else:
    print("CUDA not available!")

if is_notebook():
    from nbdev.showdoc import *

# Cell
class RetinaNetModule(LightningModule):

    def __init__(self, num_classes:int=1, img_sz=128, lr:float=1e-2, test=False):
        LightningModule.__init__(self)
        self.model = retinanet_resnet50_fpn(pretrained=False, num_classes=num_classes+1, pretrained_backbone=True)
        self.img_sz = img_sz
        self.lr = lr
        self.test = test

        # Hacked to avoid model builtin call to GeneralizedRCNNTransform.normalize() as already done in augmentation pipeline
        def noop_normalize(image): return image

        # Hacked to avoid model builtin call to GeneralizedRCNNTransform.resize() as already done in augmentation pipeline
        def noop_resize(image, target): return image, target

        # HACK!! IceVision does this too!
        self.model.transform.normalize = noop_normalize
        self.model.transform.resize = noop_resize

    def _set_grad(self, mod:module, requires_grad:bool=True):
        for param in mod.parameters():
            param.requires_grad = requires_grad

    def freeze_head(self):
        self._set_grad(self.model.head, requires_grad=False)

    def unfreeze_head(self):
        self._set_grad(self.model.head, requires_grad=True)

    def freeze_backbone(self):
        self._set_grad(self.model.backbone, requires_grad=False)

    def unfreeze_backbone(self):
        self._set_grad(self.model.backbone, requires_grad=True)

    def freeze_batchnorm(self):
        for m in self.model.modules():
            if type(m) is torch.nn.BatchNorm2d:
                self._set_grad(m, requires_grad=False)

    def unfreeze_batchnorm(self):
        for m in self.model.modules():
            if type(m) is torch.nn.BatchNorm2d:
                self._set_grad(m, requires_grad=True)

    def training_step(self, train_batch, batch_idx):
        if self.test: print('Entering training_step')
        self.model.cuda()
        xs, ys = train_batch
        safe_xs, safe_ys = [], []
        for x, y in zip(xs, ys):
            if len(y.get('boxes',[])) <= 0:
                print(f"Warning: Removing X,Y as Y has no boxes! {y}")
            else:
                safe_xs.append(x)
                safe_ys.append(y)
        if len(safe_xs) <= 0:
            return 0
        else:
            self.model.train()
            losses = self.model.forward(safe_xs, safe_ys)
            loss = sum(losses.values())
            if self.test: print(f'Exiting training_step, returning {loss}')
            return loss # has 2 types of losses: classification, bbox_regression

    def metrics(self, preds, targets):
        metrics = torch.zeros((min(len(preds), len(targets)), 2))
        for i, (p,t) in enumerate(zip(preds, targets)):
            metrics[i,0] = calc_wavg_F1(p, t, .5, .5)
            metrics[i,1] = SubCocoWrapper(p, t, self.img_sz, self.img_sz).metrics()[0]
        return metrics

    def validation_step(self, val_batch, batch_idx):
        if self.test: print('Entering validation_step')
        self.model.cpu()
        self.model.eval()

        # turn off auto gradient for validation step
        with torch.no_grad():
            xs, ys = val_batch
            xs_cpu = [ x.cpu() for x in xs ]
            ys_cpu = [ { k:v.cpu() for k,v in y.items() } for y in ys ]
            preds = self.model(xs_cpu)
            metrics = self.metrics(preds, ys)

            self.model.train()
            losses = self.model(xs_cpu, ys_cpu)

        result = {'val_acc': metrics[:,0].mean(), 'val_coco': metrics[:,1].mean(), 'val_loss': sum(losses.values())}
        if self.test: print(f'Exiting validation_step, returning {result}')
        return result

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)
        return optimizer

    def validation_epoch_end(self, outputs):
        if self.test: print('Entering validation_epoch_end')
        tensorboard_logs ={}
        avg_acc = sum([ o['val_acc'] for o in outputs ])/len(outputs)
        tensorboard_logs['val_acc'] = avg_acc

        avg_coco = sum([ o['val_coco'] for o in outputs ])/len(outputs)
        tensorboard_logs['val_coco'] = avg_coco

        avg_loss = sum([ o['val_loss'] for o in outputs ])/len(outputs)
        tensorboard_logs['val_loss'] = avg_loss
        print(f"Epoch end avg val_acc = {avg_acc} (F1 @ IoU>.5, Score>.5), avg val_coco = {avg_coco}, avg val_loss = {avg_loss}")
        result = {'val_acc': avg_acc, 'val_coco': avg_coco, 'val_loss': avg_loss, 'logs': tensorboard_logs}
        if self.test: print(f'Exiting validation_epoch_end, returning {result}')
        self.log_dict(result)

    def forward(self, imgs):
        self.model.eval()
        return self.model.forward(imgs)

# Cell
def run_training(stats:CocoDatasetStats, modeldir:str, img_dir:str, resume_ckpt_fname:str=None,
                 img_sz=384, bs=12, acc=4, workers=4, head_runs=50, full_runs=200,
                 monitor='val_acc', mode='max', save_top=-1, test=False):

    resume_ckpt = f'{modeldir}/{resume_ckpt_fname}' if resume_ckpt_fname != None else None
    if resume_ckpt and os.path.isfile(resume_ckpt):
        try:
            print(f'Loading previously saved model: {resume_ckpt}...')
            retnet_model = RetinaNetModule.load_from_checkpoint(resume_ckpt, num_classes=len(stats.lbl2name), img_sz=img_sz)
        except Exception as e:
            print(f'Unexpected error loading previously saved model {resume_ckpt}: {e}')
            retnet_model = RetinaNetModule(num_classes=len(stats.lbl2name), img_sz=img_sz, test=test)
    else:
        if resume_ckpt: print(f'Failed to find {resume_ckpt}')
        retnet_model = RetinaNetModule(num_classes=len(stats.lbl2name), img_sz=img_sz, test=test)


    print(f"Training with image size {img_sz}, auto learning rate, for {head_runs}+{full_runs} epochs.")
    head_chkpt_cb = ModelCheckpoint(
        filename='RETNET-HEAD-subcoco-'+str(img_sz)+'-{epoch:03d}-{'+monitor+':.3f}',
        dirpath=modeldir,
        save_last=True,
        monitor=monitor,
        mode=mode,
        save_top_k=save_top,
        verbose=True,
    )
    full_chkpt_cb = ModelCheckpoint(
        filename='RETNET-FULL-subcoco-'+str(img_sz)+'-{epoch:03d}-{'+monitor+':.3f}',
        dirpath=modeldir,
        save_last=True,
        monitor=monitor,
        mode=mode,
        save_top_k=save_top,
        verbose=True,
    )
    early_stop_cb = EarlyStopping(
       monitor=monitor,
       min_delta=0.001,
       patience=20,
       verbose=True,
       mode=mode
    )
    gpumon_cb = PyTorchGpuMonitorCallback(delay=1)
    callbacks = [early_stop_cb, gpumon_cb]

    # transforms for images
    bbox_aware_train_tfms=A.Compose([
        A.ShiftScaleRotate(shift_limit=.01, scale_limit=0.05, rotate_limit=9),
        A.Resize(width=img_sz, height=img_sz),
        A.HorizontalFlip(p=0.5),
        A.RGBShift(),
        A.RandomBrightnessContrast(),
        A.Blur(blur_limit=(1, 3)),
        #A.Normalize(mean=stats.chn_means/255, std=stats.chn_stds/255)
    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))

    bbox_aware_val_tfms=A.Compose([
        A.Resize(width=img_sz, height=img_sz),
        #A.Normalize(mean=stats.chn_means/255, std=stats.chn_stds/255)
    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))

    # train head only, since using less params, double the bs and half the grad accumulation cycle to use more GPU VRAM
    if head_runs > 0:
        head_dm = SubCocoDataModule(img_dir, stats, shuffle=False,
                                    train_transforms=bbox_aware_train_tfms, val_transforms=bbox_aware_val_tfms,
                                    bs=bs, workers=workers)
        trainer = Trainer(gpus=1, auto_lr_find=True, max_epochs=head_runs, default_root_dir = 'models',
                          callbacks=callbacks, checkpoint_callback=head_chkpt_cb, accumulate_grad_batches=acc)
        retnet_model.unfreeze_head()
        retnet_model.freeze_backbone()
        retnet_model.unfreeze_batchnorm()
        trainer.fit(retnet_model, head_dm)

    if full_runs > 0:
        # finetune head and backbone
        full_dm = SubCocoDataModule(img_dir, stats, shuffle=False,
                                    train_transforms=bbox_aware_train_tfms, val_transforms=bbox_aware_val_tfms,
                                    bs=bs, workers=workers)
        trainer = Trainer(gpus=1, auto_lr_find=True, max_epochs=full_runs, default_root_dir = 'models',
                          callbacks=callbacks, checkpoint_callback=full_chkpt_cb, accumulate_grad_batches=acc)
        retnet_model.unfreeze_head()
        retnet_model.unfreeze_backbone()
        retnet_model.unfreeze_batchnorm()
        trainer.fit(retnet_model, full_dm)

    if full_runs > 0:
        last_model_fpath=Path(full_chkpt_cb.last_model_path)
        saved_last_model_fpath=str(last_model_fpath.parent/f'retnet-subcoco-{img_sz}-last')+last_model_fpath.suffix
        os.rename(str(last_model_fpath), saved_last_model_fpath)

    return retnet_model, saved_last_model_fpath

# Cell
def save_final(retnet_model, model_save_path):
    torch.save(retnet_model.model.state_dict(), model_save_path)