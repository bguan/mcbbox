# AUTOGENERATED! DO NOT EDIT! File to edit: 40_subcoco_effdet_lightning.ipynb (unless otherwise specified).

__all__ = ['EffDetModule', 'run_training', 'save_final']

# Cell
import cv2, json, os, requests, sys, tarfile, torch, torchvision
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import numpy as np
import pickle
import random
import torch.nn.functional as F
import torch.multiprocessing

from collections import defaultdict
from functools import reduce
from IPython.utils import io
from pathlib import Path
from PIL import Image
from PIL import ImageStat

from pycocotools.coco import COCO
from pycocotools.cocoeval import COCOeval
from torch.nn.modules import module
from tqdm import tqdm
from typing import Hashable, List, Tuple, Union

# Cell
import albumentations as A
import pytorch_lightning as pl
from albumentations.pytorch import ToTensorV2
from effdet.config.model_config import get_efficientdet_config
from effdet.factory import create_model
from effdet.bench import DetBenchPredict, DetBenchTrain, unwrap_bench
from effdet.loss import DetectionLoss, loss_fn
from gpumonitor.monitor import GPUStatMonitor
from gpumonitor.callbacks.lightning import PyTorchGpuMonitorCallback
from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping
from pytorch_lightning import LightningDataModule, LightningModule, Trainer
from pytorch_lightning.core.step_result import TrainResult
from torch import nn
from torch import optim
from torch.utils.data import DataLoader, random_split
from torchvision import transforms
from .subcoco_utils import *
from .subcoco_lightning_utils import *

torch.multiprocessing.set_sharing_strategy('file_system')
print(f"Python ver {sys.version}, torch {torch.__version__}, torchvision {torchvision.__version__}, pytorch_lightning {pl.__version__}, Albumentation {A.__version__}")
if torch.cuda.is_available():
    monitor = GPUStatMonitor(delay=1)
else:
    print("CUDA not available!")

if is_notebook():
    from nbdev.showdoc import *

# Cell
class EffDetModule(LightningModule):

    def __init__(self, backbone_name:str="tf_efficientdet_lite0", num_classes=1, img_sz=128, lr:float=1e-2, bs=1, test=False):
        LightningModule.__init__(self)
        self.model =  create_model(
            backbone_name,
            bench_task='',
            num_classes=num_classes + 1,
            pretrained=False,
            pretrained_backbone=True,
            bench_labeler=True,
        )
        self.num_classes = num_classes
        self.config = get_efficientdet_config(model_name=backbone_name)
        self.img_sz = img_sz
        self.lr = lr
        self.loss_fn = DetectionLoss(self.config)
        self.bs = bs
        self.test = test

    def _set_grad(self, mod:module, requires_grad:bool=True):
        for param in mod.parameters():
            param.requires_grad = requires_grad

    def _get_main_model(self):
        main_mod = self.model
        if type(main_mod) is DetBenchPredict or type(main_mod) is DetBenchTrain:
            main_mod = main_mod.model
        return main_mod

    def _get_heads(self):
        main_mod = self._get_main_model()
        return [main_mod.class_net, main_mod.box_net]

    def _get_backbone(self):
        main_mod = self._get_main_model()
        return main_mod.backbone

    def freeze_head(self):
        for head_net in self._get_heads():
            self._set_grad(head_net, requires_grad=False)

    def unfreeze_head(self):
        for head_net in self._get_heads():
            self._set_grad(head_net, requires_grad=True)

    def freeze_backbone(self):
        self._set_grad(self._get_backbone(), requires_grad=False)

    def unfreeze_backbone(self):
        self._set_grad(self._get_backbone(), requires_grad=True)

    def freeze_batchnorm(self):
        for m in self.model.modules():
            if type(m) is torch.nn.BatchNorm2d:
                self._set_grad(m, requires_grad=False)

    def unfreeze_batchnorm(self):
        for m in self.model.modules():
            if type(m) is torch.nn.BatchNorm2d:
                self._set_grad(m, requires_grad=True)

    def convert_raw_predictions(self, raw_preds: torch.Tensor, detection_threshold: float=0) -> List[dict]:
        #print(f"raw_preds ={raw_preds}")
        dets = raw_preds.detach().cpu().numpy()
        preds = []
        for det in dets:
            if detection_threshold > 0:
                scores = det[:, 4]
                keep = scores > detection_threshold
                det = det[keep]
            pred = {
                "boxes": det[:, :4].clip(0, self.img_sz),
                "scores": det[:, 4],
                "labels": det[:, 5].astype(int),
            }
            preds.append(pred)

        return preds

    def fix_boxes_batch(self, xs, ys):
        safe_xs, safe_ys = [], []
        for x, y in zip(xs, ys):
            n_boxs = len(y.get('boxes',[]))
            n_cls = len(y.get('labels',[]))
            if n_boxs <= 0:
                print(f"Warning: Removing X,Y as Y has no boxes! {y}")
            elif n_boxs != n_cls:
                print(f"Warning: Removing X,Y as Y n_nboxs {n_boxs} != n_cls {n_cls}")
            else:
                bs = y['boxes'] # should be Tensor of shape bs x 4
                # clamping min max value of x1,x2,y1,y2
                for bi in range(len(bs)):
                    bs[bi, 0] = clamp_fn(0, self.img_sz-2)(bs[bi, 0].item())
                    bs[bi, 1] = clamp_fn(0, self.img_sz-2)(bs[bi, 1].item())
                    bs[bi, 2] = clamp_fn(bs[bi, 0].item()+1, self.img_sz-1)(bs[bi, 2].item())
                    bs[bi, 3] = clamp_fn(bs[bi, 1].item()+1, self.img_sz-1)(bs[bi, 3].item())
                safe_xs.append(x)
                safe_ys.append(y)
        return safe_xs, safe_ys

    def stack_images(self, xs):
        xs_stack = torch.stack([xs[i] if i < len(xs) else torch.zeros((3, self.img_sz, self.img_sz)) for i in range(self.bs)])
        return xs_stack

    def pack_target(self, ys):
        target = dict(
            bbox=[ys[yi]['boxes'] if yi < len(ys) else torch.zeros((1,4)).cuda() for yi in range(self.bs)],
            cls=[ys[yi]['labels'] if yi < len(ys) else torch.Tensor([-1]).cuda() for yi in range(self.bs)]
        )
        return target

    def training_step(self, train_batch, batch_idx):
        if self.test: print('Entering training_step')
        self.model.train()
        bench = DetBenchTrain(unwrap_bench(self.model))
        bench.cuda()
        xs, ys = self.fix_boxes_batch(*train_batch)
        if len(xs) <= 0: return 0

        target = self.pack_target(ys)
        xs_stack = self.stack_images(xs)
        losses = bench(xs_stack, target)['loss']
        if self.test: print(f'Exiting training_step, returning {losses}')
        return losses

    def metrics(self, preds, targets):
        metrics = torch.zeros((min(len(preds), len(targets)), 2))
        for i, (p,t) in enumerate(zip(preds, targets)):
            metrics[i,0] = calc_wavg_F1(p, t, .5, .5)
            metrics[i,1] = SubCocoWrapper(p, t, self.img_sz, self.img_sz).metrics()[0]
        return metrics

    def validation_step(self, val_batch, batch_idx):
        if self.test: print('Entering validation_step')
        bench = DetBenchTrain(unwrap_bench(self.model))
        bench.cuda()
        # turn off auto gradient for validation step
        with torch.no_grad():
            xs, ys = val_batch
            predictor = DetBenchPredict(unwrap_bench(self.model))
            predictor.cuda()
            raw_preds = predictor(torch.stack(xs).cuda())
            preds = self.convert_raw_predictions(raw_preds)
            metrics = self.metrics(preds, ys)

            target = self.pack_target(ys)
            xs_stack = self.stack_images(xs)
            losses = bench(xs_stack, target)['loss']

        result = {'val_acc': metrics[:,0].mean(), 'val_coco': metrics[:,1].mean(), 'val_loss': losses}
        if self.test: print(f'Exiting validation_step, returning {result}')
        return result

    def configure_optimizers(self):
        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)
        return optimizer

    def validation_epoch_end(self, outputs):
        if self.test: print('Entering validation_epoch_end')
        tensorboard_logs ={}
        avg_acc = sum([ o['val_acc'] for o in outputs ])/len(outputs)
        tensorboard_logs['val_acc'] = avg_acc

        avg_coco = sum([ o['val_coco'] for o in outputs ])/len(outputs)
        tensorboard_logs['val_coco'] = avg_coco

        avg_loss = sum([ o['val_loss'] for o in outputs ])/len(outputs)
        tensorboard_logs['val_loss'] = avg_loss
        print(f"Epoch end avg val_acc = {avg_acc} (F1 @ IoU>.5, Score>.5), avg val_coco = {avg_coco}, avg val_loss = {avg_loss}")
        result = {'val_acc': avg_acc, 'val_coco': avg_coco, 'val_loss': avg_loss, 'logs': tensorboard_logs}
        if self.test: print(f'Exiting validation_epoch_end, returning {result}')
        self.log_dict(result)

    def forward(self, imgs):
        self.model.eval()
        bench = DetBenchPredict(unwrap_bench(self.model))
        raw_preds = bench(torch.stack(imgs))
        preds = self.convert_raw_predictions(raw_preds)
        return preds

# Cell
def run_training(stats:CocoDatasetStats, modeldir:str, img_dir:str, resume_ckpt_fname:str=None,
                 img_sz=384, bs=12, acc=4, workers=4, head_runs=50, full_runs=200,
                 monitor='val_acc', mode='max', save_top=-1, test=False):

    print(f"Training with image size {img_sz}, auto learning rate, for {head_runs}+{full_runs} epochs.")
    head_chkpt_cb = ModelCheckpoint(
        filename='EFFDET-HEAD-subcoco-'+str(img_sz)+'-{epoch:03d}-{'+monitor+':.3f}',
        dirpath=modeldir,
        save_last=True,
        monitor=monitor,
        mode=mode,
        save_top_k=save_top,
        verbose=True,
    )
    full_chkpt_cb = ModelCheckpoint(
        filename='EFFDET-FULL-subcoco-'+str(img_sz)+'-{epoch:03d}-{'+monitor+':.3f}',
        dirpath=modeldir,
        save_last=True,
        monitor=monitor,
        mode=mode,
        save_top_k=save_top,
        verbose=True,
    )
    early_stop_cb = EarlyStopping(
       monitor=monitor,
       min_delta=0.001,
       patience=20,
       verbose=True,
       mode=mode
    )
    gpumon_cb = PyTorchGpuMonitorCallback(delay=1)
    callbacks = [early_stop_cb, gpumon_cb]
    resume_ckpt = f'{modeldir}/{resume_ckpt_fname}' if resume_ckpt_fname != None else None
    if resume_ckpt and os.path.isfile(resume_ckpt):
        try:
            print(f'Loading previously saved model: {resume_ckpt}...')
            effdet_model = EffDetModule.load_from_checkpoint(resume_ckpt, bs=bs, num_classes=len(stats.lbl2name), img_sz=img_sz)
        except Exception as e:
            print(f'Unexpected error loading previously saved model {resume_ckpt}: {e}')
            effdet_model = EffDetModule(backbone_name='tf_efficientdet_lite0', bs=bs, num_classes=len(stats.lbl2name), img_sz=img_sz, test=test)
    else:
        if resume_ckpt: print(f'Failed to find {resume_ckpt}')
        effdet_model = EffDetModule(backbone_name='tf_efficientdet_lite0', bs=bs, num_classes=len(stats.lbl2name), img_sz=img_sz, test=test)

    # transforms for images
    bbox_aware_train_tfms=A.Compose([
        A.ShiftScaleRotate(shift_limit=.01, scale_limit=0.05, rotate_limit=9),
        A.Resize(width=img_sz, height=img_sz),
        A.HorizontalFlip(p=0.5),
        A.RGBShift(),
        A.RandomBrightnessContrast(),
        A.Blur(blur_limit=(1, 3)),
        #A.Normalize(mean=stats.chn_means/255, std=stats.chn_stds/255)
    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))

    bbox_aware_val_tfms=A.Compose([
        A.Resize(width=img_sz, height=img_sz),
        #A.Normalize(mean=stats.chn_means/255, std=stats.chn_stds/255)
    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))

    # train head only, since using less params, double the bs and half the grad accumulation cycle to use more GPU VRAM
    if head_runs > 0:
        head_dm = SubCocoDataModule(img_dir, stats, shuffle=False,
                                    train_transforms=bbox_aware_train_tfms, val_transforms=bbox_aware_val_tfms,
                                    bs=bs*2, workers=workers)
        trainer = Trainer(gpus=1, auto_lr_find=True, max_epochs=head_runs, default_root_dir = 'models',
                          callbacks=callbacks, checkpoint_callback=head_chkpt_cb, accumulate_grad_batches=acc//2)
        effdet_model.unfreeze_head()
        effdet_model.freeze_backbone()
        effdet_model.unfreeze_batchnorm()
        trainer.fit(effdet_model, head_dm)

    if full_runs > 0:
        # finetune head and backbone
        full_dm = SubCocoDataModule(img_dir, stats, shuffle=False,
                                    train_transforms=bbox_aware_train_tfms, val_transforms=bbox_aware_val_tfms,
                                    bs=bs, workers=workers)
        trainer = Trainer(gpus=1, auto_lr_find=True, max_epochs=full_runs, default_root_dir = 'models',
                          callbacks=callbacks, checkpoint_callback=full_chkpt_cb, accumulate_grad_batches=acc)
        effdet_model.unfreeze_head()
        effdet_model.unfreeze_backbone()
        effdet_model.unfreeze_batchnorm()
        trainer.fit(effdet_model, full_dm)

    saved_last_model_fpath = None
    if full_runs > 0:
        last_model_fpath=Path(full_chkpt_cb.last_model_path)
        saved_last_model_fpath=str(last_model_fpath.parent/f'effdet-subcoco-{img_sz}-last')+last_model_fpath.suffix
        os.rename(str(last_model_fpath), saved_last_model_fpath)

    return effdet_model, saved_last_model_fpath

# Cell
def save_final(effdet_model, model_save_path):
    torch.save(effdet_model.model.state_dict(), model_save_path)